# 1 "/home/p4/Blink/p4_code/main.p4"
# 1 "<built-in>"
# 1 "<command-line>"
# 1 "/home/p4/Blink/p4_code/main.p4"
# 1 "/usr/local/share/p4c/p4include/core.p4" 1
/*
Copyright 2013-present Barefoot Networks, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/* This is the P4-16 core library, which declares some built-in P4 constructs using P4 */




/// Standard error codes.  New error codes can be declared by users.
error {
    NoError, /// No error.
    PacketTooShort, /// Not enough bits in packet for 'extract'.
    NoMatch, /// 'select' expression has no matches.
    StackOutOfBounds, /// Reference to invalid element of a header stack.
    HeaderTooShort, /// Extracting too many bits into a varbit field.
    ParserTimeout, /// Parser execution time limit exceeded.
    ParserInvalidArgument /// Parser operation was called with a value
                           /// not supported by the implementation.
}

extern packet_in {
    /// Read a header from the packet into a fixed-sized header @hdr and advance the cursor.
    /// May trigger error PacketTooShort or StackOutOfBounds.
    /// @T must be a fixed-size header type
    void extract<T>(out T hdr);
    /// Read bits from the packet into a variable-sized header @variableSizeHeader
    /// and advance the cursor.
    /// @T must be a header containing exactly 1 varbit field.
    /// May trigger errors PacketTooShort, StackOutOfBounds, or HeaderTooShort.
    void extract<T>(out T variableSizeHeader,
                    in bit<32> variableFieldSizeInBits);
    /// Read bits from the packet without advancing the cursor.
    /// @returns: the bits read from the packet.
    /// T may be an arbitrary fixed-size type.
    T lookahead<T>();
    /// Advance the packet cursor by the specified number of bits.
    void advance(in bit<32> sizeInBits);
    /// @return packet length in bytes.  This method may be unavailable on
    /// some target architectures.
    bit<32> length();
}

extern packet_out {
    /// Write @hdr into the output packet, advancing cursor.
    /// @T can be a header type, a header stack, a header_union, or a struct
    /// containing fields with such types.
    void emit<T>(in T hdr);
}

// TODO: remove from this file, convert to built-in
/// Check a predicate @check in the parser; if the predicate is true do nothing,
/// otherwise set the parser error to @toSignal, and transition to the `reject` state.
extern void verify(in bool check, in error toSignal);

/// Built-in action that does nothing.
action NoAction() {}

/// Standard match kinds for table key fields.
/// Some architectures may not support all these match kinds.
/// Architectures can declare additional match kinds.
match_kind {
    /// Match bits exactly.
    exact,
    /// Ternary match, using a mask.
    ternary,
    /// Longest-prefix match.
    lpm
}
# 2 "/home/p4/Blink/p4_code/main.p4" 2
# 1 "/usr/local/share/p4c/p4include/v1model.p4" 1
/*
Copyright 2013-present Barefoot Networks, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/* P4-16 declaration of the P4 v1.0 switch model */

/* Note 1: More details about the definition of v1model architecture
 * can be found at the location below.
 *
 * https://github.com/p4lang/behavioral-model/blob/master/docs/simple_switch.md
 *
 * Note 2: There are ongoing discussions among P4 working group
 * members in 2019-Apr regarding exactly how resubmit, recirculate,
 * and clone3 operations can be called anywhere in their respective
 * controls, but the values of the fields to be preserved is the value
 * they have when that control is finished executing.  That is how
 * these operations behave in P4_14, but this requires some care in
 * making this happen in P4_16.
 *
 * Note 3: There are at least some P4_14 implementations where
 * invoking a generate_digest operation on a field_list will create a
 * message to the control plane that contains the values of those
 * fields when the ingress control is finished executing, which can be
 * different than the values those fields have at the time the
 * generate_digest operation is invoked in the program, if those field
 * values are changed later in the execution of the P4_14 ingress
 * control.
 *
 * The P4_16 plus v1model implementation should always create digest
 * messages that contain the values of the specified fields at the
 * time that the digest extern function is called.  Thus if a P4_14
 * program expecting the behavior described above is compiled using
 * p4c, it may behave differently.
 */




# 1 "/usr/local/share/p4c/p4include/core.p4" 1
/*
Copyright 2013-present Barefoot Networks, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/* This is the P4-16 core library, which declares some built-in P4 constructs using P4 */
# 52 "/usr/local/share/p4c/p4include/v1model.p4" 2

match_kind {
    range,
    // Used for implementing dynamic_action_selection
    selector
}

// Are these correct?
@metadata @name("standard_metadata")
struct standard_metadata_t {
    bit<9> ingress_port;
    bit<9> egress_spec;
    bit<9> egress_port;
    bit<32> instance_type;
    bit<32> packet_length;
    //
    // @alias is used to generate the field_alias section of the BMV2 JSON.
    // Field alias creates a mapping from the metadata name in P4 program to
    // the behavioral model's internal metadata name. Here we use it to
    // expose all metadata supported by simple switch to the user through
    // standard_metadata_t.
    //
    // flattening fields that exist in bmv2-ss
    // queueing metadata
    @alias("queueing_metadata.enq_timestamp")
    bit<32> enq_timestamp;
    @alias("queueing_metadata.enq_qdepth")
    bit<19> enq_qdepth;
    @alias("queueing_metadata.deq_timedelta")
    bit<32> deq_timedelta;
    /// queue depth at the packet dequeue time.
    @alias("queueing_metadata.deq_qdepth")
    bit<19> deq_qdepth;

    // intrinsic metadata
    @alias("intrinsic_metadata.ingress_global_timestamp")
    bit<48> ingress_global_timestamp;
    @alias("intrinsic_metadata.egress_global_timestamp")
    bit<48> egress_global_timestamp;
    /// multicast group id (key for the mcast replication table)
    @alias("intrinsic_metadata.mcast_grp")
    bit<16> mcast_grp;
    /// Replication ID for multicast
    @alias("intrinsic_metadata.egress_rid")
    bit<16> egress_rid;
    /// Indicates that a verify_checksum() method has failed.
    /// 1 if a checksum error was found, otherwise 0.
    bit<1> checksum_error;
    /// Error produced by parsing
    error parser_error;
    /// set packet priority
    @alias("intrinsic_metadata.priority")
    bit<3> priority;
}

enum CounterType {
    packets,
    bytes,
    packets_and_bytes
}

enum MeterType {
    packets,
    bytes
}

extern counter {
    /***
     * A counter object is created by calling its constructor.  This
     * creates an array of counter states, with the number of counter
     * states specified by the size parameter.  The array indices are
     * in the range [0, size-1].
     *
     * You must provide a choice of whether to maintain only a packet
     * count (CounterType.packets), only a byte count
     * (CounterType.bytes), or both (CounterType.packets_and_bytes).
     */
    counter(bit<32> size, CounterType type);
    /***
     * count() causes the counter state with the specified index to be
     * read, modified, and written back, atomically relative to the
     * processing of other packets, updating the packet count, byte
     * count, or both, depending upon the CounterType of the counter
     * instance used when it was constructed.
     *
     * @param index The index of the counter state in the array to be
     *              updated, normally a value in the range [0,
     *              size-1].  If index >= size, no counter state will be
     *              updated.
     */
    void count(in bit<32> index);
}

extern direct_counter {
    /***
     * A direct_counter object is created by calling its constructor.
     * You must provide a choice of whether to maintain only a packet
     * count (CounterType.packets), only a byte count
     * (CounterType.bytes), or both (CounterType.packets_and_bytes).
     * After constructing the object, you can associate it with at
     * most one table, by adding the following table property to the
     * definition of that table:
     *
     *     counters = <object_name>;
     */
    direct_counter(CounterType type);
    /***
     * The count() method is actually unnecessary in the v1model
     * architecture.  This is because after a direct_counter object
     * has been associated with a table as described in the
     * documentation for the direct_counter constructor, every time
     * the table is applied and a table entry is matched, the counter
     * state associated with the matching entry is read, modified, and
     * written back, atomically relative to the processing of other
     * packets, regardless of whether the count() method is called in
     * the body of that action.
     */
    void count();
}





extern meter {
    /***
     * A meter object is created by calling its constructor.  This
     * creates an array of meter states, with the number of meter
     * states specified by the size parameter.  The array indices are
     * in the range [0, size-1].  For example, if in your system you
     * have 128 different "flows" numbered from 0 up to 127, and you
     * want to meter each of those flows independently of each other,
     * you could do so by creating a meter object with size=128.
     *
     * You must provide a choice of whether to meter based on the
     * number of packets, regardless of their size
     * (MeterType.packets), or based upon the number of bytes the
     * packets contain (MeterType.bytes).
     */
    meter(bit<32> size, MeterType type);
    /***
     * execute_meter() causes the meter state with the specified index
     * to be read, modified, and written back, atomically relative to
     * the processing of other packets, and an integer encoding of one
     * of the colors green, yellow, or red to be written to the result
     * out parameter.
     *
     * @param index The index of the meter state in the array to be
     *              updated, normally a value in the range [0,
     *              size-1].  If index >= size, no meter state will be
     *              updated.
     * @param result Type T must be bit<W> with W >= 2.  When index is
     *              in range, the value of result will be assigned 0
     *              for color GREEN, 1 for color YELLOW, and 2 for
     *              color RED (see RFC 2697 and RFC 2698 for the
     *              meaning of these colors).  When index is out of
     *              range, the final value of result is not specified,
     *              and should be ignored by the caller.
     */
    void execute_meter<T>(in bit<32> index, out T result);
}

extern direct_meter<T> {
    /***
     * A direct_meter object is created by calling its constructor.
     * You must provide a choice of whether to meter based on the
     * number of packets, regardless of their size
     * (MeterType.packets), or based upon the number of bytes the
     * packets contain (MeterType.bytes).  After constructing the
     * object, you can associate it with at most one table, by adding
     * the following table property to the definition of that table:
     *
     *     meters = <object_name>;
     */
    direct_meter(MeterType type);
    /***
     * After a direct_meter object has been associated with a table as
     * described in the documentation for the direct_meter
     * constructor, every time the table is applied and a table entry
     * is matched, the meter state associated with the matching entry
     * is read, modified, and written back, atomically relative to the
     * processing of other packets, regardless of whether the read()
     * method is called in the body of that action.
     *
     * read() may only be called within an action executed as a result
     * of matching a table entry, of a table that has a direct_meter
     * associated with it.  Calling read() causes an integer encoding
     * of one of the colors green, yellow, or red to be written to the
     * result out parameter.
     *
     * @param result Type T must be bit<W> with W >= 2.  The value of
     *              result will be assigned 0 for color GREEN, 1 for
     *              color YELLOW, and 2 for color RED (see RFC 2697
     *              and RFC 2698 for the meaning of these colors).
     */
    void read(out T result);
}

extern register<T> {
    register(bit<32> size);
    /***
     * read() reads the state of the register array stored at the
     * specified index, and returns it as the value written to the
     * result parameter.
     *
     * @param index The index of the register array element to be
     *              read, normally a value in the range [0, size-1].
     * @param result Only types T that are bit<W> are currently
     *              supported.  When index is in range, the value of
     *              result becomes the value read from the register
     *              array element.  When index >= size, the final
     *              value of result is not specified, and should be
     *              ignored by the caller.
     */
    void read(out T result, in bit<32> index);
    /***
     * write() writes the state of the register array at the specified
     * index, with the value provided by the value parameter.
     *
     * If you wish to perform a read() followed later by a write() to
     * the same register array element, and you wish the
     * read-modify-write sequence to be atomic relative to other
     * processed packets, then there may be parallel implementations
     * of the v1model architecture for which you must execute them in
     * a P4_16 block annotated with an @atomic annotation.  See the
     * P4_16 language specification description of the @atomic
     * annotation for more details.
     *
     * @param index The index of the register array element to be
     *              written, normally a value in the range [0,
     *              size-1].  If index >= size, no register state will
     *              be updated.
     * @param value Only types T that are bit<W> are currently
     *              supported.  When index is in range, this
     *              parameter's value is written into the register
     *              array element specified by index.
     */
    void write(in bit<32> index, in T value);
}

// used as table implementation attribute
extern action_profile {
    action_profile(bit<32> size);
}

/***
 * Generate a random number in the range lo..hi, inclusive, and write
 * it to the result parameter.  The value written to result is not
 * specified if lo > hi.
 *
 * @param T          Must be a type bit<W>
 */
extern void random<T>(out T result, in T lo, in T hi);

/***
 * Calling digest causes a message containing the values specified in
 * the data parameter to be sent to the control plane software.  It is
 * similar to sending a clone of the packet to the control plane
 * software, except that it can be more efficient because the messages
 * are typically smaller than packets, and many such small digest
 * messages are typically coalesced together into a larger "batch"
 * which the control plane software processes all at once.
 *
 * The value of the fields that are sent in the message to the control
 * plane is the value they have at the time the digest call occurs,
 * even if those field values are changed by later ingress control
 * code.  See Note 3.
 *
 * Calling digest is only supported in the ingress control.  There is
 * no way to undo its effects once it has been called.
 *
 * If the type T is a named struct, the name is used to generate the
 * control plane API.
 *
 * The BMv2 implementation of the v1model architecture ignores the
 * value of the receiver parameter.
 */
extern void digest<T>(in bit<32> receiver, in T data);

enum HashAlgorithm {
    crc32,
    crc32_custom,
    crc16,
    crc16_custom,
    random,
    identity,
    csum16,
    xor16
}

@deprecated("Please use mark_to_drop(standard_metadata) instead.")
extern void mark_to_drop();

/***
 * mark_to_drop(standard_metadata) is a primitive action that modifies
 * standard_metadata.egress_spec to an implementation-specific special
 * value that in some cases causes the packet to be dropped at the end
 * of ingress or egress processing.  It also assigns 0 to
 * standard_metadata.mcast_grp.  Either of those metadata fields may
 * be changed by executing later P4 code, after calling
 * mark_to_drop(), and this can change the resulting behavior of the
 * packet to do something other than drop.
 *
 * See
 * https://github.com/p4lang/behavioral-model/blob/master/docs/simple_switch.md
 * -- in particular the section "Pseudocode for what happens at the
 * end of ingress and egress processing" -- for the relative priority
 * of the different possible things that can happen to a packet when
 * ingress and egress processing are complete.
 */
extern void mark_to_drop(inout standard_metadata_t standard_metadata);

/***
 * Calculate a hash function of the value specified by the data
 * parameter.  The value written to the out parameter named result
 * will always be in the range [base, base+max-1] inclusive, if max >=
 * 1.  If max=0, the value written to result will always be base.
 *
 * Note that the types of all of the parameters may be the same as, or
 * different from, each other, and thus their bit widths are allowed
 * to be different.
 *
 * @param O          Must be a type bit<W>
 * @param D          Must be a tuple type where all the fields are bit-fields (type bit<W> or int<W>) or varbits.
 * @param T          Must be a type bit<W>
 * @param M          Must be a type bit<W>
 */
extern void hash<O, T, D, M>(out O result, in HashAlgorithm algo, in T base, in D data, in M max);

extern action_selector {
    action_selector(HashAlgorithm algorithm, bit<32> size, bit<32> outputWidth);
}

enum CloneType {
    I2E,
    E2E
}

@deprecated("Please use verify_checksum/update_checksum instead.")
extern Checksum16 {
    Checksum16();
    bit<16> get<D>(in D data);
}

/***
 * Verifies the checksum of the supplied data.  If this method detects
 * that a checksum of the data is not correct, then the value of the
 * standard_metadata checksum_error field will be equal to 1 when the
 * packet begins ingress processing.
 *
 * Calling verify_checksum is only supported in the VerifyChecksum
 * control.
 *
 * @param T          Must be a tuple type where all the tuple elements
 *                   are of type bit<W>, int<W>, or varbit<W>.  The
 *                   total length of the fields must be a multiple of
 *                   the output size.
 * @param O          Checksum type; must be bit<X> type.
 * @param condition  If 'false' the verification always succeeds.
 * @param data       Data whose checksum is verified.
 * @param checksum   Expected checksum of the data; note that it must
 *                   be a left-value.
 * @param algo       Algorithm to use for checksum (not all algorithms
 *                   may be supported).  Must be a compile-time
 *                   constant.
 */
extern void verify_checksum<T, O>(in bool condition, in T data, inout O checksum, HashAlgorithm algo);

/***
 * Computes the checksum of the supplied data and writes it to the
 * checksum parameter.
 *
 * Calling update_checksum is only supported in the ComputeChecksum
 * control.
 *
 * @param T          Must be a tuple type where all the tuple elements
 *                   are of type bit<W>, int<W>, or varbit<W>.  The
 *                   total length of the fields must be a multiple of
 *                   the output size.
 * @param O          Output type; must be bit<X> type.
 * @param condition  If 'false' the checksum parameter is not changed
 * @param data       Data whose checksum is computed.
 * @param checksum   Checksum of the data.
 * @param algo       Algorithm to use for checksum (not all algorithms
 *                   may be supported).  Must be a compile-time
 *                   constant.
 */
extern void update_checksum<T, O>(in bool condition, in T data, inout O checksum, HashAlgorithm algo);

/***
 * verify_checksum_with_payload is identical in all ways to
 * verify_checksum, except that it includes the payload of the packet
 * in the checksum calculation.  The payload is defined as "all bytes
 * of the packet which were not parsed by the parser".
 *
 * Calling verify_checksum_with_payload is only supported in the
 * VerifyChecksum control.
 */
extern void verify_checksum_with_payload<T, O>(in bool condition, in T data, inout O checksum, HashAlgorithm algo);

/**
 * update_checksum_with_payload is identical in all ways to
 * update_checksum, except that it includes the payload of the packet
 * in the checksum calculation.  The payload is defined as "all bytes
 * of the packet which were not parsed by the parser".
 *
 * Calling update_checksum_with_payload is only supported in the
 * ComputeChecksum control.
 */
extern void update_checksum_with_payload<T, O>(in bool condition, in T data, inout O checksum, HashAlgorithm algo);

/***
 * Calling resubmit during execution of the ingress control will,
 * under certain documented conditions, cause the packet to be
 * resubmitted, i.e. it will begin processing again with the parser,
 * with the contents of the packet exactly as they were when it last
 * began parsing.  The only difference is in the value of the
 * standard_metadata instance_type field, and any user-defined
 * metadata fields that the resubmit operation causes to be
 * preserved.
 *
 * The value of the user-defined metadata fields that are preserved in
 * resubmitted packets is the value they have at the end of ingress
 * processing, not their values at the time the resubmit call is made.
 * See Note 2.
 *
 * Calling resubmit is only supported in the ingress control.  There
 * is no way to undo its effects once it has been called.  If resubmit
 * is called multiple times during a single execution of the ingress
 * control, only one packet is resubmitted, and only the data from the
 * last such call is preserved.  See the v1model architecture
 * documentation (Note 1) for more details.
 */
extern void resubmit<T>(in T data);

/***
 * Calling recirculate during execution of the egress control will,
 * under certain documented conditions, cause the packet to be
 * recirculated, i.e. it will begin processing again with the parser,
 * with the contents of the packet as they are created by the
 * deparser.  Recirculated packets can be distinguished from new
 * packets in ingress processing by the value of the standard_metadata
 * instance_type field.  The caller may request that some user-defined
 * metadata fields be preserved with the recirculated packet.
 *
 * The value of the user-defined metadata fields that are preserved in
 * recirculated packets is the value they have at the end of egress
 * processing, not their values at the time the recirculate call is
 * made.  See Note 2.
 *
 * Calling recirculate is only supported in the egress control.  There
 * is no way to undo its effects once it has been called.  If
 * recirculate is called multiple times during a single execution of
 * the egress control, only one packet is recirculated, and only the
 * data from the last such call is preserved.  See the v1model
 * architecture documentation (Note 1) for more details.
 */
extern void recirculate<T>(in T data);

/***
 * clone is in most ways identical to the clone3 operation, with the
 * only difference being that it never preserves any user-defined
 * metadata fields with the cloned packet.  It is equivalent to
 * calling clone3 with the same type and session parameter values,
 * with empty data.
 */
extern void clone(in CloneType type, in bit<32> session);

/***
 * Calling clone3 during execution of the ingress or egress control
 * will cause the packet to be cloned, sometimes also called
 * mirroring, i.e. zero or more copies of the packet are made, and
 * each will later begin egress processing as an independent packet
 * from the original packet.  The original packet continues with its
 * normal next steps independent of the clone(s).
 *
 * The session parameter is an integer identifying a clone session id
 * (sometimes called a mirror session id).  The control plane software
 * must configure each session you wish to use, or else no clones will
 * be made using that session.  Typically this will involve the
 * control plane software specifying one output port to which the
 * cloned packet should be sent, or a list of (port, egress_rid) pairs
 * to which a separate clone should be created for each, similar to
 * multicast packets.
 *
 * Cloned packets can be distinguished from others by the value of the
 * standard_metadata instance_type field.
 *
 * The caller may request that some user-defined metadata field values
 * from the original packet should be preserved with the cloned
 * packet(s).  The value of the user-defined metadata fields that are
 * preserved with cloned packets is the value they have at the end of
 * ingress or egress processing, not their values at the time the
 * clone3 call is made.  See Note 2.
 *
 * If clone3 is called during ingress processing, the first parameter
 * must be CloneType.I2E.  If clone3 is called during egress
 * processing, the first parameter must be CloneType.E2E.
 *
 * There is no way to undo its effects once it has been called.  If
 * there are multiple calls to clone3 and/or clone during a single
 * execution of the same ingress (or egress) control, only the last
 * clone session and data are used.  See the v1model architecture
 * documentation (Note 1) for more details.
 */
extern void clone3<T>(in CloneType type, in bit<32> session, in T data);

extern void truncate(in bit<32> length);

/***
 * Calling assert when the argument is true has no effect, except any
 * effect that might occur due to evaluation of the argument (but see
 * below).  If the argument is false, the precise behavior is
 * target-specific, but the intent is to record or log which assert
 * statement failed, and optionally other information about the
 * failure.
 *
 * For example, on the simple_switch target, executing an assert
 * statement with a false argument causes a log message with the file
 * name and line number of the assert statement to be printed, and
 * then the simple_switch process exits.
 *
 * If you provide the --ndebug command line option to p4c when
 * compiling, the compiled program behaves as if all assert statements
 * were not present in the source code.
 *
 * We strongly recommend that you avoid using expressions as an
 * argument to an assert call that can have side effects, e.g. an
 * extern method or function call that has side effects.  p4c will
 * allow you to do this with no warning given.  We recommend this
 * because, if you follow this advice, your program will behave the
 * same way when assert statements are removed.
 */
extern void assert(in bool check);

/***
 * For the purposes of compiling and executing P4 programs on a target
 * device, assert and assume are identical, including the use of the
 * --ndebug p4c option to elide them.  See documentation for assert.
 *
 * The reason that assume exists as a separate function from assert is
 * because they are expected to be used differently by formal
 * verification tools.  For some formal tools, the goal is to try to
 * find example packets and sets of installed table entries that cause
 * an assert statement condition to be false.
 *
 * Suppose you run such a tool on your program, and the example packet
 * given is an MPLS packet, i.e. hdr.ethernet.etherType == 0x8847.
 * You look at the example, and indeed it does cause an assert
 * condition to be false.  However, your plan is to deploy your P4
 * program in a network in places where no MPLS packets can occur.
 * You could add extra conditions to your P4 program to handle the
 * processing of such a packet cleanly, without assertions failing,
 * but you would prefer to tell the tool "such example packets are not
 * applicable in my scenario -- never show them to me".  By adding a
 * statement:
 *
 *     assume(hdr.ethernet.etherType != 0x8847);
 *
 * at an appropriate place in your program, the formal tool should
 * never show you such examples -- only ones that make all such assume
 * conditions true.
 *
 * The reason that assume statements behave the same as assert
 * statements when compiled to a target device is that if the
 * condition ever evaluates to false when operating in a network, it
 * is likely that your assumption was wrong, and should be reexamined.
 */
extern void assume(in bool check);

// The name 'standard_metadata' is reserved

/*
 * Architecture.
 *
 * M must be a struct.
 *
 * H must be a struct where every one if its members is of type
 * header, header stack, or header_union.
 */

parser Parser<H, M>(packet_in b,
                    out H parsedHdr,
                    inout M meta,
                    inout standard_metadata_t standard_metadata);

/*
 * The only legal statements in the body of the VerifyChecksum control
 * are: block statements, calls to the verify_checksum and
 * verify_checksum_with_payload methods, and return statements.
 */
control VerifyChecksum<H, M>(inout H hdr,
                             inout M meta);
@pipeline
control Ingress<H, M>(inout H hdr,
                      inout M meta,
                      inout standard_metadata_t standard_metadata);
@pipeline
control Egress<H, M>(inout H hdr,
                     inout M meta,
                     inout standard_metadata_t standard_metadata);

/*
 * The only legal statements in the body of the ComputeChecksum
 * control are: block statements, calls to the update_checksum and
 * update_checksum_with_payload methods, and return statements.
 */
control ComputeChecksum<H, M>(inout H hdr,
                              inout M meta);

/*
 * The only legal statements in the body of the Deparser control are:
 * calls to the packet_out.emit() method.
 */
@deparser
control Deparser<H>(packet_out b, in H hdr);

package V1Switch<H, M>(Parser<H, M> p,
                       VerifyChecksum<H, M> vr,
                       Ingress<H, M> ig,
                       Egress<H, M> eg,
                       ComputeChecksum<H, M> ck,
                       Deparser<H> dep
                       );
# 3 "/home/p4/Blink/p4_code/main.p4" 2

# 1 "/home/p4/Blink/p4_code/includes/headers.p4" 1
typedef bit<48> EthernetAddress;
typedef bit<32> IPv4Address;

// standard Ethernet header
header Ethernet_h {
    EthernetAddress dstAddr;
    EthernetAddress srcAddr;
    bit<16> etherType;
}

// IPv4 header without options
header IPv4_h {
    bit<4> version;
    bit<4> ihl;
    bit<6> dscp;
    bit<2> ecn;
    bit<16> totalLen;
    bit<16> identification;
    bit<3> flags;
    bit<13> fragOffset;
    bit<8> ttl;
    bit<8> protocol;
    bit<16> hdrChecksum;
    IPv4Address srcAddr;
    IPv4Address dstAddr;
}

header TCP_h {
    bit<16> srcPort;
    bit<16> dstPort;
    bit<32> seqNo;
    bit<32> ackNo;
    bit<4> dataOffset;
    bit<4> res;
    bit<1> cwr;
    bit<1> ece;
    bit<1> urg;
    bit<1> ack;
    bit<1> psh;
    bit<1> rst;
    bit<1> syn;
    bit<1> fin;
    bit<16> window;
    bit<16> checksum;
    bit<16> urgentPtr;
}

header ICMP_h {
   bit<8> type;
   bit<8> code;
   bit<16> checksum;
   bit<32> unused;
}

struct Parsed_packet {
    Ethernet_h ethernet;
    IPv4_h ipv4_icmp;
    ICMP_h icmp;
    IPv4_h ipv4;
    TCP_h tcp;
}
# 5 "/home/p4/Blink/p4_code/main.p4" 2
# 1 "/home/p4/Blink/p4_code/includes/metadata.p4" 1
struct controller_metadata_t {
 bit<1> toController;
 bit<32> code;
}

struct custom_metadata_t {
    // Metadata used in the normal pipeline
    bit<32> id;
    // bit<1> matched;
    bit<1> use_blink;


    bit<1> is_retransmission;

    // Metadata used for the next-hops
    bit<32> next_hop_port;
    IPv4Address nhop_ipv4;

    bit<16> tcp_payload_len;

    // Metadata to handle the timestamps for the flowcache
    bit<9> ingress_timestamp_second;
    bit<19> ingress_timestamp_millisecond;

    // Metadata used by the FlowCache
    bit<32> flowselector_cellid;

    bit<1> selected;

    bit<2> bgp_ngh_type;

    bit<32> bl_value;

    bit<32> reg_check;

    bit<6> threshold_check;

    bit<1> syn_flag;

    bit<1> fin_flag;

    bit<1> rst_flag;

    bit<1> ack_flag;

    bit<32> src_addr;

    bit<32> dst_addr;
}
# 6 "/home/p4/Blink/p4_code/main.p4" 2
# 1 "/home/p4/Blink/p4_code/includes/parser.p4" 1



parser ParserImpl(packet_in pkt_in, out Parsed_packet pp,
    inout custom_metadata_t meta,
    inout standard_metadata_t standard_metadata) {

    state start {
        pkt_in.extract(pp.ethernet);
        transition select(pp.ethernet.etherType) {
            16w0x800: parse_ipv4;
            // no default rule: all other packets rejected
        }
    }

    state parse_ipv4 {
        pkt_in.extract(pp.ipv4);
        transition select(pp.ipv4.protocol) {
            8w6: parse_tcp;
            default: accept;
        }
    }

    state parse_tcp {
        pkt_in.extract(pp.tcp);

        transition accept;
    }
}
# 7 "/home/p4/Blink/p4_code/main.p4" 2
# 1 "/home/p4/Blink/p4_code/includes/macros.p4" 1
// Maximum number of prefixes


// Macros for the per flow retransmission detector component


// Macros for the maximum flows selection time


// Macros for the size of Counting Bloom Filter used for the flow filter


// Macros for the sliding window



// Macros for the flowselector




// Two offsets for obtain to different hash functions from the crc32 hash function



// Number of progressing flows required in order to classify a nexthop as working




// Macro used to reply to traceroutes
# 8 "/home/p4/Blink/p4_code/main.p4" 2

# 1 "/home/p4/Blink/p4_code/pipeline/flowselector.p4" 1
# 1 "/home/p4/Blink/p4_code/pipeline/../includes/macros.p4" 1
// Maximum number of prefixes


// Macros for the per flow retransmission detector component


// Macros for the maximum flows selection time


// Macros for the size of Counting Bloom Filter used for the flow filter


// Macros for the sliding window



// Macros for the flowselector




// Two offsets for obtain to different hash functions from the crc32 hash function



// Number of progressing flows required in order to classify a nexthop as working




// Macro used to reply to traceroutes
# 2 "/home/p4/Blink/p4_code/pipeline/flowselector.p4" 2

control flowselector(inout Parsed_packet pp,
    inout custom_metadata_t custom_metadata,
    inout standard_metadata_t standard_metadata,
    in register<bit<32>> flowselector_key, // Could be just 16 or something bits
    in register<bit<32>> flowselector_nep,
    in register<bit<9>> flowselector_ts,
    in register<bit<19>> flowselector_last_ret,
    in register<bit<4>> flowselector_last_ret_bin,
    in register<bit<1>> flowselector_correctness,
    in register<bit<2>> flowselector_fwloops,
    in register<bit<6>> sw,
    in register<bit<19>> sw_time,
    in register<bit<4>> sw_index,
    in register<bit<6>> sw_sum,
    in register<bit<6>> nbflows_progressing_2,
    in register<bit<6>> nbflows_progressing_3,
    in register<bit<19>> rerouting_ts)
{
    bit<32> newflow_key;
    bit<32> cell_id;

    bit<32> curflow_key;
    bit<9> curflow_ts;
    bit<32> curflow_nep;
    bit<19> ts_tmp;

    bit<4> index_tmp;
    bit<6> bin_value_tmp;
    bit<6> sum_tmp;
    bit<19> time_tmp;

    bit<32> flowselector_index;
    bit<19> last_ret_ts;
    bit<4> index_prev;

    bit<19> rerouting_ts_tmp;
    bit<1> flowselector_correctness_tmp;
    bit<6> correctness_tmp;

    apply {

# 1 "/home/p4/Blink/p4_code/pipeline/sliding_window.p4" 1
// This file is included in flowselector.p4

// Variables used for the sliding window
bit<19> last_sw_time;
bit<4> cur_sw_index;
bit<6> cur_sw_sum;
bit<6> cur_sw_val;

bit<48> shift;
custom_metadata.bl_value = custom_metadata.bl_value + 28;
sw_time.read(last_sw_time, custom_metadata.id);

// If the sliding window is too late by 1s or more, re initialize it
if (custom_metadata.ingress_timestamp_millisecond - last_sw_time > ((bit<19>)(48w80000 >> 10))*(bit<19>)(4w10))
{
    custom_metadata.bl_value= custom_metadata.bl_value + 980448;
    sw_time.write(custom_metadata.id, custom_metadata.ingress_timestamp_millisecond);
    sw_index.write(custom_metadata.id, 0);
    sw_sum.write(custom_metadata.id, 0);
    sw.write((custom_metadata.id*(bit<32>)4w10)+0, 0);
    sw.write((custom_metadata.id*(bit<32>)4w10)+1, 0);
    sw.write((custom_metadata.id*(bit<32>)4w10)+2, 0);
    sw.write((custom_metadata.id*(bit<32>)4w10)+3, 0);
    sw.write((custom_metadata.id*(bit<32>)4w10)+4, 0);
    sw.write((custom_metadata.id*(bit<32>)4w10)+5, 0);
    sw.write((custom_metadata.id*(bit<32>)4w10)+6, 0);
    sw.write((custom_metadata.id*(bit<32>)4w10)+7, 0);
    sw.write((custom_metadata.id*(bit<32>)4w10)+8, 0);
    sw.write((custom_metadata.id*(bit<32>)4w10)+9, 0);
}

sw_time.read(last_sw_time, custom_metadata.id);
sw_index.read(cur_sw_index, custom_metadata.id);
sw_sum.read(cur_sw_sum, custom_metadata.id);


if (custom_metadata.ingress_timestamp_millisecond - last_sw_time > ((bit<19>)(48w80000 >> 10)))
{
    shift = 0;
    custom_metadata.bl_value= custom_metadata.bl_value + 672;
    // Compute the shift (without division)
    // Basically same as     shift = (custom_metadata.ingress_timestamp_millisecond - last_sw_time)/SW_BINS_DURATION;
    if (custom_metadata.ingress_timestamp_millisecond - last_sw_time < ((bit<19>)(48w80000 >> 10)))
    {
        custom_metadata.bl_value= custom_metadata.bl_value + 163296;
        shift = 0;
    }
    else if (custom_metadata.ingress_timestamp_millisecond - last_sw_time < 2*((bit<19>)(48w80000 >> 10)))
    {
        custom_metadata.bl_value= custom_metadata.bl_value + 653184;
        shift = 1;
    }
    else if (custom_metadata.ingress_timestamp_millisecond - last_sw_time < 3*((bit<19>)(48w80000 >> 10)))
    {
        custom_metadata.bl_value= custom_metadata.bl_value + 489888;
        shift = 2;
    }
    else if (custom_metadata.ingress_timestamp_millisecond - last_sw_time < 4*((bit<19>)(48w80000 >> 10)))
    {
        shift = 3;
    }
    else if (custom_metadata.ingress_timestamp_millisecond - last_sw_time < 5*((bit<19>)(48w80000 >> 10)))
    {
        custom_metadata.bl_value= custom_metadata.bl_value + 163296;
        shift = 4;
    }
    else
    {

        shift = 5;
    }

    if (shift > 0)
    {
        // Increase the timestamp by a bin time
        custom_metadata.bl_value= custom_metadata.bl_value + 54432;
        last_sw_time = last_sw_time + ((bit<19>)(48w80000 >> 10));
        // Move to the next index
        cur_sw_index = cur_sw_index + 4w1;
        if (cur_sw_index >= 4w10)
        {
            custom_metadata.bl_value= custom_metadata.bl_value + 54432;
            cur_sw_index = 0;
        }

        // Read the value in the current bin of the Sliding window
        sw.read(cur_sw_val, (custom_metadata.id*(bit<32>)4w10)+(bit<32>)cur_sw_index);
        // Remove from the global sum that value
        cur_sw_sum = cur_sw_sum - cur_sw_val;
        // Set 0 into the new bin
        sw.write((custom_metadata.id*(bit<32>)4w10)+(bit<32>)cur_sw_index, 0);

        // Decrease shift by one
        shift = shift - 1;
    }

    if (shift > 0)
    {
        custom_metadata.bl_value = custom_metadata.bl_value + 18144;
        last_sw_time = last_sw_time + ((bit<19>)(48w80000 >> 10));
        cur_sw_index = cur_sw_index + 4w1;
        if (cur_sw_index >= 4w10)
        {
            custom_metadata.bl_value= custom_metadata.bl_value+18144;
            cur_sw_index = 0;
        }

        sw.read(cur_sw_val, (custom_metadata.id*(bit<32>)4w10)+(bit<32>)cur_sw_index);
        cur_sw_sum = cur_sw_sum - cur_sw_val;
        sw.write((custom_metadata.id*(bit<32>)4w10)+(bit<32>)cur_sw_index, 0);
        shift = shift - 1;
    }
    if (shift > 0)
    {
        custom_metadata.bl_value= custom_metadata.bl_value + 12096;
        last_sw_time = last_sw_time + ((bit<19>)(48w80000 >> 10));
        cur_sw_index = cur_sw_index + 4w1;
        if (cur_sw_index >= 4w10)
        {
            custom_metadata.bl_value= custom_metadata.bl_value + 6048;
            cur_sw_index = 0;
        }

        sw.read(cur_sw_val, (custom_metadata.id*(bit<32>)4w10)+(bit<32>)cur_sw_index);
        cur_sw_sum = cur_sw_sum - cur_sw_val;
        sw.write((custom_metadata.id*(bit<32>)4w10)+(bit<32>)cur_sw_index, 0);

        shift = shift - 1;
    }
    if (shift > 0)
    {
        custom_metadata.bl_value = custom_metadata.bl_value + 2016;
        last_sw_time = last_sw_time + ((bit<19>)(48w80000 >> 10));
        cur_sw_index = cur_sw_index + 4w1;
        if (cur_sw_index >= 4w10)
        {
            custom_metadata.bl_value = custom_metadata.bl_value + 2016;
            cur_sw_index = 0;
        }

        sw.read(cur_sw_val, (custom_metadata.id*(bit<32>)4w10)+(bit<32>)cur_sw_index);
        cur_sw_sum = cur_sw_sum - cur_sw_val;
        sw.write((custom_metadata.id*(bit<32>)4w10)+(bit<32>)cur_sw_index, 0);

        shift = shift - 1;
    }
    if (shift > 0)
    {
        custom_metadata.bl_value = custom_metadata.bl_value + 1344;
        last_sw_time = last_sw_time + ((bit<19>)(48w80000 >> 10));
        cur_sw_index = cur_sw_index + 4w1;
        if (cur_sw_index >= 4w10)
        {
            custom_metadata.bl_value = custom_metadata.bl_value + 672;
            cur_sw_index = 0;
        }

        sw.read(cur_sw_val, (custom_metadata.id*(bit<32>)4w10)+(bit<32>)cur_sw_index);
        cur_sw_sum = cur_sw_sum - cur_sw_val;
        sw.write((custom_metadata.id*(bit<32>)4w10)+(bit<32>)cur_sw_index, 0);

        shift = shift - 1;
    }

    sw_time.write(custom_metadata.id, last_sw_time);
    sw_index.write(custom_metadata.id, cur_sw_index);
    sw_sum.write(custom_metadata.id, cur_sw_sum);
}
# 45 "/home/p4/Blink/p4_code/pipeline/flowselector.p4" 2

        // Compute the hash for the flow key
        hash(newflow_key, HashAlgorithm.crc32, (bit<16>)0,
            {pp.ipv4.srcAddr, pp.ipv4.dstAddr, pp.tcp.srcPort, pp.tcp.dstPort, 32w2134}, (bit<32>)(64w4294967296 -1));

        newflow_key = newflow_key + 1;

        // Compute the hash for the cell id
        hash(cell_id, HashAlgorithm.crc32, (bit<16>)0,
            {pp.ipv4.srcAddr, pp.ipv4.dstAddr, pp.tcp.srcPort, pp.tcp.dstPort, 32w56097}, (bit<32>)32w64);


        custom_metadata.flowselector_cellid = cell_id;

        flowselector_index = (custom_metadata.id * 32w64) + cell_id;
        flowselector_key.read(curflow_key, flowselector_index);
        flowselector_ts.read(curflow_ts, flowselector_index);
        flowselector_nep.read(curflow_nep, flowselector_index);

        rerouting_ts.read(rerouting_ts_tmp, custom_metadata.id);

        if (curflow_key == newflow_key && custom_metadata.ingress_timestamp_second >= curflow_ts)
        {
            custom_metadata.bl_value=custom_metadata.bl_value + 224;
            custom_metadata.selected = 1w1;

            if (pp.tcp.fin == 1w1)
            {
                // Retrieve the timestamp of the last retransmission
                custom_metadata.bl_value= custom_metadata.bl_value + 336;
                flowselector_last_ret.read(last_ret_ts, flowselector_index);

                // Retrieve the timestamp of the current bin
                sw_time.read(time_tmp, custom_metadata.id);

                // If there was a retransmission during the last time window:
                // remove it from the sliding window
                if (((bit<48>)(custom_metadata.ingress_timestamp_millisecond - last_ret_ts)) <
                    (bit<48>)((bit<19>)(4w10 -1)*(((bit<19>)(48w80000 >> 10)))
                    + (custom_metadata.ingress_timestamp_millisecond - time_tmp))
                    && last_ret_ts > 0)
                {
                    custom_metadata.bl_value=custom_metadata.bl_value + 56;
                    // Read the value of the previous index used for the previous retransmission
                    flowselector_last_ret_bin.read(index_prev, flowselector_index);

                    // Decrement the value in the previous bin in the sliding window,
                    // as well as the total sum
                    sw.read(bin_value_tmp, (custom_metadata.id*(bit<32>)4w10)+(bit<32>)index_prev);
                    sw_sum.read(sum_tmp, custom_metadata.id);

                    sw.write((custom_metadata.id*(bit<32>)4w10)+(bit<32>)index_prev, bin_value_tmp-1);
                    sw_sum.write(custom_metadata.id, sum_tmp-1);
                }


                flowselector_key.write(flowselector_index, 32w0);
                flowselector_nep.write(flowselector_index, 32w0);
                flowselector_ts.write(flowselector_index, 9w0);
                flowselector_last_ret.write(flowselector_index, 19w0);
                flowselector_correctness.write(flowselector_index, 1w0);
                flowselector_fwloops.write(flowselector_index, 2w0);
            }
            else
            {
                // If it is a RETRANSMISSION
                if (curflow_nep == pp.tcp.seqNo + (bit<32>)custom_metadata.tcp_payload_len)
                {
                    // Indicate that this packet is a retransmssion
                    custom_metadata.is_retransmission = 1;

                    // Retrieve the timestamp of the last retransmission
                    flowselector_last_ret.read(last_ret_ts, flowselector_index);

                    // Retrieve the timestamp of the current bin
                    sw_time.read(time_tmp, custom_metadata.id);

                    if (((bit<48>)(custom_metadata.ingress_timestamp_millisecond - last_ret_ts)) <
                        (bit<48>)((bit<19>)(4w10 -1)*(((bit<19>)(48w80000 >> 10)))
                        + (custom_metadata.ingress_timestamp_millisecond - time_tmp))
                        && last_ret_ts > 0)
                    {
                        // Read the value of the previous index used for the previous retransmission
                        custom_metadata.bl_value= custom_metadata.bl_value + 56;
                        flowselector_last_ret_bin.read(index_prev, flowselector_index);

                        // First, decrement the value in the previous bin in the sliding window
                        sw.read(bin_value_tmp, (custom_metadata.id*(bit<32>)4w10)+(bit<32>)index_prev);
                        sw_sum.read(sum_tmp, custom_metadata.id);

                        sw.write((custom_metadata.id*(bit<32>)4w10)+(bit<32>)index_prev, bin_value_tmp-1);
                        sw_sum.write(custom_metadata.id, sum_tmp-1);
                    }

                    // Then, increment the value in the current bin of the sliding window
                    sw_index.read(index_tmp, custom_metadata.id);
                    sw.read(bin_value_tmp, (custom_metadata.id*(bit<32>)4w10)+(bit<32>)index_tmp);
                    sw_sum.read(sum_tmp, custom_metadata.id);

                    sw.write((custom_metadata.id*(bit<32>)4w10)+(bit<32>)index_tmp, bin_value_tmp+1);
                    sw_sum.write(custom_metadata.id, sum_tmp+1);

                    // Update the timestamp of the last retransmission in the flowselector
                    sw_time.read(time_tmp, custom_metadata.id);
                    flowselector_last_ret.write(flowselector_index, custom_metadata.ingress_timestamp_millisecond);

                    // Read the value of the previous index used for the previous retransmission
                    flowselector_last_ret_bin.write(flowselector_index, index_tmp);
                }
                // If it is not a retransmission: Update the correctness register (if blink has rerouted)
                else if (rerouting_ts_tmp > 19w0 && custom_metadata.ingress_timestamp_millisecond
                    - rerouting_ts_tmp < (bit<19>)(48w1000000 >> 10))
                {
                    custom_metadata.bl_value = custom_metadata.bl_value + 112;
                    flowselector_correctness.read(flowselector_correctness_tmp,
                        (custom_metadata.id * 32w64) + custom_metadata.flowselector_cellid);

                    if (flowselector_correctness_tmp == 1w0)
                    {
                        if (custom_metadata.flowselector_cellid < 32)
                        {
                            custom_metadata.bl_value = custom_metadata.bl_value + 56;
                            nbflows_progressing_2.read(correctness_tmp, custom_metadata.id);
                            nbflows_progressing_2.write(custom_metadata.id, correctness_tmp+1);
                        }
                        else
                        {
                            nbflows_progressing_3.read(correctness_tmp, custom_metadata.id);
                            nbflows_progressing_3.write(custom_metadata.id, correctness_tmp+1);
                        }
                    }
                    custom_metadata.bl_value= custom_metadata.bl_value + 112;
                    flowselector_correctness.write(
                        (custom_metadata.id * 32w64) + custom_metadata.flowselector_cellid, 1w1);
                }
                custom_metadata.bl_value= custom_metadata.bl_value + 168;

                flowselector_ts.write(flowselector_index, custom_metadata.ingress_timestamp_second);
                flowselector_nep.write(flowselector_index, pp.tcp.seqNo + (bit<32>)custom_metadata.tcp_payload_len);
            }
        }
        else
        {
            if (((curflow_key == 0) || (custom_metadata.ingress_timestamp_second
                - curflow_ts) > 9w2 || custom_metadata.ingress_timestamp_second
                < curflow_ts) && pp.tcp.fin == 1w0)
            {
                custom_metadata.selected = 1w1;

                if (curflow_key > 0)
                {
                    custom_metadata.bl_value = custom_metadata.bl_value + 112;
                    // Retrieve the timestamp of the last retransmission
                    flowselector_last_ret.read(last_ret_ts, flowselector_index);

                    // Retrieve the timestamp of the current bin
                    sw_time.read(time_tmp, custom_metadata.id);

                    // If there was a retransmission during the last time window:
                    // remove it from the sliding window
                    if (((bit<48>)(custom_metadata.ingress_timestamp_millisecond - last_ret_ts)) <
                        (bit<48>)((bit<19>)(4w10 -1)*(((bit<19>)(48w80000 >> 10)))
                        + (custom_metadata.ingress_timestamp_millisecond - time_tmp))
                        && last_ret_ts > 0)
                    {
                        // Read the value of the previous index used for the previous retransmission
                        flowselector_last_ret_bin.read(index_prev, flowselector_index);
                        custom_metadata.bl_value= custom_metadata.bl_value + 56;

                        // Decrement the value in the previous bin in the sliding window,
                        // as well as the total sum
                        sw.read(bin_value_tmp, (custom_metadata.id*(bit<32>)4w10)+(bit<32>)index_prev);
                        sw_sum.read(sum_tmp, custom_metadata.id);

                        sw.write((custom_metadata.id*(bit<32>)4w10)+(bit<32>)index_prev, bin_value_tmp-1);
                        sw_sum.write(custom_metadata.id, sum_tmp-1);
                    }

                }
                flowselector_key.write(flowselector_index, newflow_key);
                flowselector_nep.write(flowselector_index, pp.tcp.seqNo + (bit<32>)custom_metadata.tcp_payload_len);
                flowselector_ts.write(flowselector_index, custom_metadata.ingress_timestamp_second);
                flowselector_last_ret.write(flowselector_index, 19w0);
                flowselector_correctness.write(flowselector_index, 1w0);
                flowselector_fwloops.write(flowselector_index, 2w0);
            }
        }
    }
}
# 10 "/home/p4/Blink/p4_code/main.p4" 2


control ingress(inout Parsed_packet pp,
                inout custom_metadata_t custom_metadata,
                inout standard_metadata_t standard_metadata)
{
    // register<bit<32> >(1000) my_Reg;

    register<bit<32>>(32w100*32w64) flowselector_key;
    register<bit<32>>(32w100*32w64) flowselector_nep;
    register<bit<9>>(32w100*32w64) flowselector_ts;
    register<bit<19>>(32w100*32w64) flowselector_last_ret;
    register<bit<4>>(32w100*32w64) flowselector_last_ret_bin;
    register<bit<1>>(32w100*32w64) flowselector_correctness;
    register<bit<2>>(32w100*32w64) flowselector_fwloops;
    /** Registers used by the sliding window **/
    register<bit<6>>(32w100*(bit<32>)(4w10)) sw;
    register<bit<19>>(32w100) sw_time;
    register<bit<4>>(32w100) sw_index;
    register<bit<6>>(32w100) sw_sum;

    // Register to store the threshold for each prefix (by default all the prefixes
    // have the same threshold, so this could just be a macro)
    register<bit<6>>(32w100) threshold_registers;

    // List of next-hops for each prefix
    register<bit<32>>(32w100*3) next_hops_port;

    // Register used to indicate whether a next-hop is working or not.
    register<bit<1>>(32w100) nh_avaibility_1;
    register<bit<1>>(32w100) nh_avaibility_2;
    register<bit<1>>(32w100) nh_avaibility_3;

    // Register use to keep track for each flow, the number of flows that restart
    // after the rerouting. One per backup next-hop
    register<bit<6>>(32w100) nbflows_progressing_2;
    register<bit<6>>(32w100) nbflows_progressing_3;

    // Timestamp of the rerouting
    register<bit<19>>(32w100) rerouting_ts;

    // Every time period seconds (define by MAX_FLOWS_SELECTION_TIME), the
    // controller updates this register
    register<bit<48>>(32w1) timestamp_reference;

    // Switch IP used to reply to the traceroutes
    register<bit<32>>(32w1) switch_ip;


    register<bit<32>>(1024) reg_bl_code;

    register<bit<32>>(1024) bl_count;

    bit<9> ts_second;

    bit<48> ts_tmp;
    bit<6> sum_tmp;
    bit<6> threshold_tmp;
    bit<6> correctness_tmp;
    bit<19> rerouting_ts_tmp;
    bit<2> flowselector_fwloops_tmp;
    bit<1> nh_avaibility_1_tmp;
    bit<1> nh_avaibility_2_tmp;
    bit<1> nh_avaibility_3_tmp;

    bit<32> threshold_check;

    bit<32> temp_count;

    bit<32> collision_check;
    flowselector() fc;

    /**
    * Mark packet to drop
    */
    action _drop() {
        mark_to_drop(standard_metadata);
    }
    action bl_drop()
    {
        custom_metadata.bl_value= custom_metadata.bl_value + 3921877;
        mark_to_drop(standard_metadata);
    }

    /**
    * Set the metadata used in the normal pipeline
    */
    action set_meta(bit<32> id, bit<1> use_blink, bit<32> default_nexthop_port) {
        custom_metadata.id = id;
        custom_metadata.use_blink = use_blink;
        custom_metadata.next_hop_port = default_nexthop_port;
    }

    table meta_fwtable {
        actions = {
            set_meta;
            bl_drop;
            // _drop;
        }
        key =
        {
            pp.ipv4.dstAddr: lpm;
            custom_metadata.bgp_ngh_type: exact;
        }
        size = 20000;
        default_action=bl_drop;
        // default_action = _drop;
    }


    /**
    * Set the metadata about BGP (provider, peer or customer)
    */
    action set_bgp_tag(bit<2> neighbor_bgp_type)
    {
        custom_metadata.bgp_ngh_type = neighbor_bgp_type;
        custom_metadata.bl_value= custom_metadata.bl_value + 7843754;
    }
    action update_val_no_action()
    {
        custom_metadata.bl_value= custom_metadata.bl_value + 15687508;
    }
    table debug
    {
      key=
      {
        custom_metadata.bl_value:exact;
        custom_metadata.syn_flag:exact;
        custom_metadata.fin_flag:exact;
        custom_metadata.rst_flag:exact;
        custom_metadata.src_addr:exact;
        custom_metadata.dst_addr:exact;
        custom_metadata.ack_flag:exact;
        custom_metadata.next_hop_port:exact;
        custom_metadata.reg_check:exact;
        custom_metadata.threshold_check:exact;


      }
      actions=
      {
        NoAction;
      }
      const default_action = NoAction;
    }
    table bgp_tag {
        actions = {
            set_bgp_tag;
            // NoAction;
            update_val_no_action;
        }
        key = {
            standard_metadata.ingress_port: exact;
            pp.ethernet.srcAddr: exact;
        }
        size = 20000;

       // default_action = update_val; // By default bgp_ngh_type will be 0, meaning customer (used for the host)
       default_action= update_val_no_action;
    }

    /**
    * Set output port and destination MAC address based on port ID
    */
    action set_nh(bit<9> port, EthernetAddress smac, EthernetAddress dmac)
    {
        standard_metadata.egress_spec = port;
        pp.ethernet.srcAddr = smac;
        pp.ethernet.dstAddr = dmac;
        // Decrement the TTL by one
        pp.ipv4.ttl = pp.ipv4.ttl - 1;
    }

    table send {
        actions = {
            set_nh;
            _drop;
        }
        key = {
            custom_metadata.next_hop_port: exact;
        }
        size = 1024;
        default_action = _drop;
    }

    // /** Registers used by the Flow Selector **/
    // register<bit<32>>(MAX_NB_PREFIXES*FLOWSELECTOR_NBFLOWS) flowselector_key;
    // register<bit<32>>(MAX_NB_PREFIXES*FLOWSELECTOR_NBFLOWS) flowselector_nep;
    // register<bit<9>>(MAX_NB_PREFIXES*FLOWSELECTOR_NBFLOWS) flowselector_ts;
    // register<bit<19>>(MAX_NB_PREFIXES*FLOWSELECTOR_NBFLOWS) flowselector_last_ret;
    // register<bit<4>>(MAX_NB_PREFIXES*FLOWSELECTOR_NBFLOWS) flowselector_last_ret_bin;
    // register<bit<1>>(MAX_NB_PREFIXES*FLOWSELECTOR_NBFLOWS) flowselector_correctness;
    // register<bit<2>>(MAX_NB_PREFIXES*FLOWSELECTOR_NBFLOWS) flowselector_fwloops;

    // /** Registers used by the sliding window **/
    // register<bit<6>>(MAX_NB_PREFIXES*(bit<32>)(SW_NB_BINS)) sw;
    // register<bit<19>>(MAX_NB_PREFIXES) sw_time;
    // register<bit<4>>(MAX_NB_PREFIXES) sw_index;
    // register<bit<6>>(MAX_NB_PREFIXES) sw_sum;

    // // Register to store the threshold for each prefix (by default all the prefixes
    // // have the same threshold, so this could just be a macro)
    // register<bit<6>>(MAX_NB_PREFIXES) threshold_registers;

    // // List of next-hops for each prefix
    // register<bit<32>>(MAX_NB_PREFIXES*3) next_hops_port;

    // // Register used to indicate whether a next-hop is working or not.
    // register<bit<1>>(MAX_NB_PREFIXES) nh_avaibility_1;
    // register<bit<1>>(MAX_NB_PREFIXES) nh_avaibility_2;
    // register<bit<1>>(MAX_NB_PREFIXES) nh_avaibility_3;

    // // Register use to keep track for each flow, the number of flows that restart
    // // after the rerouting. One per backup next-hop
    // register<bit<6>>(MAX_NB_PREFIXES) nbflows_progressing_2;
    // register<bit<6>>(MAX_NB_PREFIXES) nbflows_progressing_3;

    // // Timestamp of the rerouting
    // register<bit<19>>(MAX_NB_PREFIXES) rerouting_ts;

    // // Every time period seconds (define by MAX_FLOWS_SELECTION_TIME), the
    // // controller updates this register
    // register<bit<48>>(32w1) timestamp_reference;

    // // Switch IP used to reply to the traceroutes
    // register<bit<32>>(32w1) switch_ip;

    // bit<9> ts_second;

    // bit<48> ts_tmp;
    // bit<6> sum_tmp;
    // bit<6> threshold_tmp;
    // bit<6> correctness_tmp;
    // bit<19> rerouting_ts_tmp;
    // bit<2> flowselector_fwloops_tmp;
    // bit<1> nh_avaibility_1_tmp;
    // bit<1> nh_avaibility_2_tmp;
    // bit<1> nh_avaibility_3_tmp;

    // flowselector() fc;

    // /**
    // * Mark packet to drop
    // */
    // action _drop() {
    //     mark_to_drop(standard_metadata);
    // }

    // /**
    // * Set the metadata used in the normal pipeline
    // */
    // action set_meta(bit<32> id, bit<1> use_blink, bit<32> default_nexthop_port) {
    //     custom_metadata.id = id;
    //     custom_metadata.use_blink = use_blink;
    //     custom_metadata.next_hop_port = default_nexthop_port;
    // }

    // table meta_fwtable {
    //     actions = {
    //         set_meta;
    //         _drop;
    //     }
    //     key = 
    //     {
    //         pp.ipv4.dstAddr: lpm;
    //         custom_metadata.bgp_ngh_type: exact;
    //     }
    //     size = 20000;
    //     default_action = _drop;
    // }


    // /**
    // * Set the metadata about BGP (provider, peer or customer)
    // */
    // action set_bgp_tag(bit<2> neighbor_bgp_type) {
    //     custom_metadata.bgp_ngh_type = neighbor_bgp_type;
    // }

    // table bgp_tag {
    //     actions = {
    //         set_bgp_tag;
    //         NoAction;
    //     }
    //     key = {
    //         standard_metadata.ingress_port: exact;
    //         pp.ethernet.srcAddr: exact;
    //     }
    //     size = 20000;
    //     default_action = NoAction; // By default bgp_ngh_type will be 0, meaning customer (used for the host)
    // }

    // /**
    // * Set output port and destination MAC address based on port ID
    // */
    // action set_nh(bit<9> port, EthernetAddress smac, EthernetAddress dmac) 
    // {
    //     standard_metadata.egress_spec = port;
    //     pp.ethernet.srcAddr = smac;
    //     pp.ethernet.dstAddr = dmac;

    //     // Decrement the TTL by one
    //     pp.ipv4.ttl = pp.ipv4.ttl - 1;
    // }

    // table send {
    //     actions = {
    //         set_nh;
    //         _drop;
    //     }
    //     key = {
    //         custom_metadata.next_hop_port: exact;
    //     }
    //     size = 1024;
    //     default_action = _drop;
    // }

    apply
    {
        timestamp_reference.read(ts_tmp, 32w0);

        custom_metadata.src_addr= pp.ipv4.srcAddr;
        custom_metadata.dst_addr=pp.ipv4.dstAddr;

        // If the difference between the reference timestamp and the current
        // timestamp is above MAX_FLOWS_SELECTION_TIME, then reference timestamp
        // is updated
        if (standard_metadata.ingress_global_timestamp - ts_tmp > 48w500000000)
        {
            custom_metadata.bl_value= custom_metadata.bl_value + 15687509;
            timestamp_reference.write(32w0, standard_metadata.ingress_global_timestamp);
        }

        timestamp_reference.read(ts_tmp, 32w0);

        custom_metadata.ingress_timestamp_second =(bit<9>)((standard_metadata.ingress_global_timestamp - ts_tmp) >> 20);
        custom_metadata.ingress_timestamp_millisecond =(bit<19>)((standard_metadata.ingress_global_timestamp - ts_tmp) >> 10);

        bgp_tag.apply();
        meta_fwtable.apply();

        if (pp.ipv4.isValid() && pp.tcp.isValid())
        {
            custom_metadata.syn_flag= pp.tcp.syn;
            custom_metadata.fin_flag= pp.tcp.fin;
            custom_metadata.rst_flag=pp.tcp.rst;
            custom_metadata.ack_flag= pp.tcp.ack;
        }

        //Traceroute Logic (only for TCP probes)
        if (pp.ipv4.isValid() && pp.tcp.isValid() && pp.ipv4.ttl == 1)
        {

            // Set new headers valid
            custom_metadata.bl_value= custom_metadata.bl_value + 3921876;
            pp.ipv4_icmp.setValid();
            pp.icmp.setValid();

            // Set egress port == ingress port
            standard_metadata.egress_spec = standard_metadata.ingress_port;

            //Ethernet: Swap map addresses
            bit<48> tmp_mac = pp.ethernet.srcAddr;
            pp.ethernet.srcAddr = pp.ethernet.dstAddr;
            pp.ethernet.dstAddr = tmp_mac;

            //Building new Ipv4 header for the ICMP packet
            //Copy original header (for simplicity)
            pp.ipv4_icmp = pp.ipv4;
            //Set destination address as traceroute originator
            pp.ipv4_icmp.dstAddr = pp.ipv4.srcAddr;
            //Set src IP to the IP assigned to the switch
            switch_ip.read(pp.ipv4_icmp.srcAddr, 0);


            // syn_flag.read(temp,0);
            // temp=temp+1;
            // syn_flag.write(0,temp);

            //Set protocol to ICMP
            pp.ipv4_icmp.protocol = 1;
            //Set default TTL
            pp.ipv4_icmp.ttl = 64;
            //And IP Length to 56 bytes (normal IP header + ICMP + 8 bytes of data)
            pp.ipv4_icmp.totalLen= 56;

            //Create ICMP header with
            pp.icmp.type = 11;
            pp.icmp.code = 0;

            //make sure all the packets are length 70.. so wireshark does not complain when tpc options,etc
            truncate((bit<32>)70);
        }
        else
        {
            // Get the threshold to use for fast rerouting (default is 32 flows)
            threshold_registers.read(threshold_tmp, custom_metadata.id);

            // If it is a TCP packet and destined to a destination that has Blink activated
            if (pp.tcp.isValid() && custom_metadata.use_blink == 1w1)
            {
                // If it is a SYN packet, then we set the tcp_payload_len to 1
                // (even if the packet actually does not have any payload)
                custom_metadata.bl_value= custom_metadata.bl_value + 3921848 ;
                if (pp.tcp.syn == 1w1 || pp.tcp.fin == 1w1)
                {
                    custom_metadata.bl_value = custom_metadata.bl_value + 1960924;
                    custom_metadata.tcp_payload_len = 16w1;
                }
                else
                    custom_metadata.tcp_payload_len = pp.ipv4.totalLen - (bit<16>)(pp.ipv4.ihl)*16w4 - (bit<16>)(pp.tcp.dataOffset)*16w4; // ip_len - ip_hdr_len - tcp_hdr_len

                if (custom_metadata.tcp_payload_len > 0)
                {
                    fc.apply(pp, custom_metadata, standard_metadata,flowselector_key, flowselector_nep, flowselector_ts,flowselector_last_ret, flowselector_last_ret_bin,flowselector_correctness, flowselector_fwloops,sw, sw_time, sw_index, sw_sum,nbflows_progressing_2,nbflows_progressing_3,rerouting_ts);
                    custom_metadata.bl_value= custom_metadata.bl_value + 168;
                    sw_sum.read(sum_tmp, custom_metadata.id);
                    nh_avaibility_1.read(nh_avaibility_1_tmp, custom_metadata.id);

                    custom_metadata.threshold_check= sum_tmp;
                    // Trigger the fast reroute if sum_tmp is greater than the
                    // threshold (i.e., default 31)
                    if (sum_tmp > threshold_tmp && nh_avaibility_1_tmp == 0)
                    {
                        // Write 1, to deactivate this next-hop
                        // and start using the backup ones
                        custom_metadata.bl_value = custom_metadata.bl_value +28;
                        nh_avaibility_1.write(custom_metadata.id, 1);

                        // Initialize the registers used to check flow progression
                        nbflows_progressing_2.write(custom_metadata.id, 6w0);
                        nbflows_progressing_3.write(custom_metadata.id, 6w0);

                        // Storing the timestamp of the rerouting
                        rerouting_ts.write(custom_metadata.id, custom_metadata.ingress_timestamp_millisecond);
                    }
                }

            }

            if (custom_metadata.use_blink == 1w1)
            {
                nh_avaibility_1.read(nh_avaibility_1_tmp, custom_metadata.id);
                nh_avaibility_2.read(nh_avaibility_2_tmp, custom_metadata.id);
                nh_avaibility_3.read(nh_avaibility_3_tmp, custom_metadata.id);
                rerouting_ts.read(rerouting_ts_tmp, custom_metadata.id);

                // All the selected flows, within the first second after the rerouting.
                if (custom_metadata.selected == 1w1 && rerouting_ts_tmp > 0 && (custom_metadata.ingress_timestamp_millisecond -rerouting_ts_tmp) < ((bit<19>)(48w1000000 >> 10)))
                {
                    // Monitoring the first backup NH
                    custom_metadata.bl_value= custom_metadata.bl_value + 8;
                    if (custom_metadata.flowselector_cellid < (32w64 >> 1))
                    {
                        // If the backup next-hop is working so far
                        custom_metadata.bl_value = custom_metadata.bl_value + 10;
                        if (nh_avaibility_2_tmp == 1w0)
                        {
                            custom_metadata.bl_value = custom_metadata.bl_value + 4;
                            next_hops_port.read(custom_metadata.next_hop_port, (custom_metadata.id*3)+1);

                            if (custom_metadata.is_retransmission == 1w1) // If this is a retransmission
                            {
                                flowselector_fwloops.read(flowselector_fwloops_tmp,(32w64 * custom_metadata.id) + custom_metadata.flowselector_cellid);
                                custom_metadata.bl_value= custom_metadata.bl_value + 4;
                                // If a forwarding loop is detected for this flow
                                if (flowselector_fwloops_tmp == 2w3)
                                {
                                    // We switch to the third backup nexthop
                                    nh_avaibility_2.write(custom_metadata.id, 1);
                                    nh_avaibility_2_tmp = 1w1;
                                }
                                else
                                {
                                    custom_metadata.bl_value= custom_metadata.bl_value + 2;
                                    flowselector_fwloops.write((32w64 * custom_metadata.id) + custom_metadata.flowselector_cellid, flowselector_fwloops_tmp + 1);
                                }
                            }
                        }
                        else
                        {
                            if (nh_avaibility_3_tmp == 1w0)
                            {
                                // Retrieve the port ID to use for that prefix
                                next_hops_port.read(custom_metadata.next_hop_port, (custom_metadata.id*3)+2);
                            }
                            else
                            {
                                custom_metadata.bl_value= custom_metadata.bl_value + 2;
                                next_hops_port.read(custom_metadata.next_hop_port, (custom_metadata.id*3)+0);
                            }
                        }

                    }
                    // Monitoring the second backup NH
                    else
                    {
                        // If the backup next-hop is working so far
                        if (nh_avaibility_3_tmp == 1w0)
                        {
                            custom_metadata.bl_value= custom_metadata.bl_value + 4;
                            next_hops_port.read(custom_metadata.next_hop_port, (custom_metadata.id*3)+2);

                            if (custom_metadata.is_retransmission == 1w1) // If this is a retransmission
                            {
                                flowselector_fwloops.read(flowselector_fwloops_tmp,(32w64 * custom_metadata.id) + custom_metadata.flowselector_cellid);

                                // If a forwarding loop is detected for this flow
                                if (flowselector_fwloops_tmp == 2w3)
                                {
                                    // We switch to the third backup nexthop
                                    nh_avaibility_3.write(custom_metadata.id, 1);
                                    nh_avaibility_3_tmp = 1w1;
                                }
                                else
                                {
                                    custom_metadata.bl_value= custom_metadata.bl_value + 2;
                                    flowselector_fwloops.write((32w64 * custom_metadata.id)
                                    + custom_metadata.flowselector_cellid, flowselector_fwloops_tmp + 1);
                                }
                            }
                        }
                        else
                        {
                            if (nh_avaibility_2_tmp == 1w0)
                            {
                                // Retrieve the port ID to use for that prefix
                                next_hops_port.read(custom_metadata.next_hop_port, (custom_metadata.id*3)+1);
                            }
                            else
                            {
                                custom_metadata.bl_value= custom_metadata.bl_value + 2;
                                next_hops_port.read(custom_metadata.next_hop_port, (custom_metadata.id*3)+0);
                            }
                        }
                    }
                }
                // Else: All the flows of the prefixes monitored by Blink
                else
                {
                    custom_metadata.bl_value= custom_metadata.bl_value + 4;
                    if (nh_avaibility_1_tmp == 1w0)
                    {
                        // Retrieve the port ID to use for that prefix
                        next_hops_port.read(custom_metadata.next_hop_port, (custom_metadata.id*3)+0);
                    }
                    else if (nh_avaibility_2_tmp == 1w0)
                    {
                        custom_metadata.bl_value = custom_metadata.bl_value + 6;
                        next_hops_port.read(custom_metadata.next_hop_port, (custom_metadata.id*3)+1);
                    }
                    else if (nh_avaibility_3_tmp == 1w0)
                    {
                        next_hops_port.read(custom_metadata.next_hop_port, (custom_metadata.id*3)+2);
                    }
                    else
                    {
                        custom_metadata.bl_value = custom_metadata.bl_value + 2;
                        // If none of the backup next-hop is working, then we use primary next-hop
                        next_hops_port.read(custom_metadata.next_hop_port, (custom_metadata.id*3)+0);
                    }
                }

                // Check if after one second at least more than half of the flows have
                // restarted otherwise deactive the corresponding next-hop

                if (rerouting_ts_tmp > 0 && (custom_metadata.ingress_timestamp_millisecond - rerouting_ts_tmp) > ((bit<19>)(48w1000000 >> 10)))
                {
                    custom_metadata.bl_value= custom_metadata.bl_value +1;
                    nbflows_progressing_2.read(correctness_tmp, custom_metadata.id);
                    if (correctness_tmp < (threshold_tmp >> 1) && nh_avaibility_2_tmp == 0)
                    {
                        nh_avaibility_2.write(custom_metadata.id, 1);
                    }
                    nbflows_progressing_3.read(correctness_tmp, custom_metadata.id);
                    if (correctness_tmp < (threshold_tmp >> 1) && nh_avaibility_3_tmp == 0)
                    {
                        nh_avaibility_3.write(custom_metadata.id, 1);
                    }
                }
            }
            // write logic for hashing the BL value
            bit<32> modulo_value= 1023;
            bit<32> index = custom_metadata.bl_value&modulo_value;

            reg_bl_code.read(collision_check,index);

            bl_count.read(temp_count,index);
            //probability of collision is 10^(-6) and we have only approx ~~ 10 distinct BL Values

            if(temp_count==0 || custom_metadata.bl_value == collision_check)
            {

                reg_bl_code.write(index,custom_metadata.bl_value);

                bl_count.read(temp_count,index);

                temp_count= temp_count + 1;

                bl_count.write(index,temp_count);

            }
            else
            { // linear probing one iteration.
                if(temp_count==0)
                {
                 // 
                    index= ((custom_metadata.bl_value + 1)&modulo_value);

                    reg_bl_code.write(index,custom_metadata.bl_value);

                    bl_count.read(temp_count,index);

                    temp_count= temp_count + 1;

                    bl_count.write(index,temp_count);
                }

            }




            // bit<32> modulo_value= 1023;
            // bit<32> index1 = custom_metadata.bl_value&modulo_value;
            // bit<32> index2 = (custom_metadata.bl_value + 1)&modulo_value;

            // bl_count.read(temp_count1,index1);
            // bl_count.read(temp_count2,index2);


            // if(temp_count==0 || custom_metadata.bl_value == collision_check)
            // {

            //     reg_bl_code.write(index,custom_metadata.bl_value);

            //     bl_count.read(temp_count,index);

            //     temp_count= temp_count + 1;

            //     bl_count.write(index,temp_count);

            // }
            // else
            // {   // linear probing one iteration.
            //     if(temp_count==0)
            //     {
            //     	// 
            //         index= ((custom_metadata.bl_value + 1)&modulo_value);

            //         reg_bl_code.write(index,custom_metadata.bl_value);

            //         bl_count.read(temp_count,index);

            //         temp_count= temp_count + 1;

            //         bl_count.write(index,temp_count);
            //     }

            // }




            send.apply();
            debug.apply();

        }
    }
}


/* ------------------------------------------------------------------------- */
control egress(inout Parsed_packet pp,
               inout custom_metadata_t custom_metadata,
               inout standard_metadata_t standard_metadata) {

   apply { }
}

/* ------------------------------------------------------------------------- */
control verifyChecksum(inout Parsed_packet pp, inout custom_metadata_t meta) {
    apply {
    }
}

/* ------------------------------------------------------------------------- */
control computeChecksum(inout Parsed_packet pp, inout custom_metadata_t meta) {
    apply {
        update_checksum(
            pp.ipv4.isValid(),
                { pp.ipv4.version,
                  pp.ipv4.ihl,
                  pp.ipv4.dscp,
                  pp.ipv4.ecn,
                  pp.ipv4.totalLen,
                  pp.ipv4.identification,
                  pp.ipv4.flags,
                  pp.ipv4.fragOffset,
                  pp.ipv4.ttl,
                  pp.ipv4.protocol,
                  pp.ipv4.srcAddr,
                  pp.ipv4.dstAddr },
                  pp.ipv4.hdrChecksum,
                  HashAlgorithm.csum16);

        update_checksum(
        pp.ipv4_icmp.isValid(),
            { pp.ipv4_icmp.version,
              pp.ipv4_icmp.ihl,
              pp.ipv4_icmp.dscp,
              pp.ipv4_icmp.ecn,
              pp.ipv4_icmp.totalLen,
              pp.ipv4_icmp.identification,
              pp.ipv4_icmp.flags,
              pp.ipv4_icmp.fragOffset,
              pp.ipv4_icmp.ttl,
              pp.ipv4_icmp.protocol,
              pp.ipv4_icmp.srcAddr,
              pp.ipv4_icmp.dstAddr },
              pp.ipv4_icmp.hdrChecksum,
              HashAlgorithm.csum16);

        update_checksum(
        pp.icmp.isValid(),
            { pp.icmp.type,
              pp.icmp.code,
              pp.icmp.unused,
              pp.ipv4.version,
              pp.ipv4.ihl,
              pp.ipv4.dscp,
              pp.ipv4.ecn,
              pp.ipv4.totalLen,
              pp.ipv4.identification,
              pp.ipv4.flags,
              pp.ipv4.fragOffset,
              pp.ipv4.ttl,
              pp.ipv4.protocol,
              pp.ipv4.hdrChecksum,
              pp.ipv4.srcAddr,
              pp.ipv4.dstAddr,
              pp.tcp.srcPort,
              pp.tcp.dstPort,
              pp.tcp.seqNo
              },
              pp.icmp.checksum,
              HashAlgorithm.csum16);
        }
}

/* ------------------------------------------------------------------------- */
control DeparserImpl(packet_out packet, in Parsed_packet pp) {
    apply {
        packet.emit(pp.ethernet);
        packet.emit(pp.ipv4_icmp);
        packet.emit(pp.icmp);
        packet.emit(pp.ipv4);
        packet.emit(pp.tcp);
    }
}

V1Switch(ParserImpl(),
    verifyChecksum(),
    ingress(),
    egress(),
    computeChecksum(),
    DeparserImpl()) main;
